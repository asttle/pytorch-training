{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyMdOAUxVOPAiAOmV0Cjaoq9"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["## Day 1 Pytorch Fundamentals"],"metadata":{"id":"i8rYhT5LIaEG"}},{"cell_type":"code","source":["import torch\n","print(torch.__version__)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QDZ1vEICIqJr","executionInfo":{"status":"ok","timestamp":1751214910637,"user_tz":-60,"elapsed":5,"user":{"displayName":"Asttle Joseph","userId":"09266131455780899081"}},"outputId":"b011981c-f802-4006-d6e4-ed168a1768e8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2.6.0+cu124\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H_1y4hfVHHne","executionInfo":{"status":"ok","timestamp":1751214910744,"user_tz":-60,"elapsed":47,"user":{"displayName":"Asttle Joseph","userId":"09266131455780899081"}},"outputId":"7a978d1d-c845-45a4-a901-569a9fd8515c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Hello lets start learning pytorch\n"]}],"source":["print('Hello lets start learning pytorch')"]},{"cell_type":"markdown","source":["Creating tensors"],"metadata":{"id":"9Rwbdp7LL57-"}},{"cell_type":"code","source":["#scalars\n","scalar = torch.tensor(7)\n","scalar.ndim"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TvTyZbg4M3RA","executionInfo":{"status":"ok","timestamp":1751214910745,"user_tz":-60,"elapsed":18,"user":{"displayName":"Asttle Joseph","userId":"09266131455780899081"}},"outputId":"987d9d9e-054d-44de-d8f9-ad7c9f389bc5"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0"]},"metadata":{},"execution_count":72}]},{"cell_type":"code","source":["# Get tensor back as python int\n","scalar.item()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dif134wUM7vP","executionInfo":{"status":"ok","timestamp":1751214910745,"user_tz":-60,"elapsed":15,"user":{"displayName":"Asttle Joseph","userId":"09266131455780899081"}},"outputId":"8122b4c1-98e6-4fbf-f5c2-a77f52a4a548"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["7"]},"metadata":{},"execution_count":73}]},{"cell_type":"code","source":["# Vector\n","vector = torch.tensor([7,7])\n","vector.ndim"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cyFBB_YRNWwl","executionInfo":{"status":"ok","timestamp":1751214910745,"user_tz":-60,"elapsed":12,"user":{"displayName":"Asttle Joseph","userId":"09266131455780899081"}},"outputId":"3349e7ef-15bf-4f0a-a2f5-1da75d1224c3"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1"]},"metadata":{},"execution_count":74}]},{"cell_type":"code","source":["vector.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"074i9XUINDdV","executionInfo":{"status":"ok","timestamp":1751214910745,"user_tz":-60,"elapsed":10,"user":{"displayName":"Asttle Joseph","userId":"09266131455780899081"}},"outputId":"cc9c03e2-b12d-4175-f717-e1e500c5d98d"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([2])"]},"metadata":{},"execution_count":75}]},{"cell_type":"code","source":["# Matrix\n","matrix = torch.tensor([[7,8],[9,10]])\n","matrix.ndim"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TNVclfkLNv_y","executionInfo":{"status":"ok","timestamp":1751214910769,"user_tz":-60,"elapsed":23,"user":{"displayName":"Asttle Joseph","userId":"09266131455780899081"}},"outputId":"11890717-b135-440f-8096-d6257ba896a8"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["2"]},"metadata":{},"execution_count":76}]},{"cell_type":"code","source":["matrix.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IANasGBnN7pn","executionInfo":{"status":"ok","timestamp":1751214910786,"user_tz":-60,"elapsed":20,"user":{"displayName":"Asttle Joseph","userId":"09266131455780899081"}},"outputId":"dd2c677f-f6c2-4aad-c828-d56b527144c0"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([2, 2])"]},"metadata":{},"execution_count":77}]},{"cell_type":"code","source":["#tensor\n","tensor = torch.tensor([[[1,2,3],[3,4,5],[5,6,7]],[[1,2,3],[2,2,1],[3,3,4]]])\n","tensor.ndim"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nZHq4lV9N-W1","executionInfo":{"status":"ok","timestamp":1751214910787,"user_tz":-60,"elapsed":19,"user":{"displayName":"Asttle Joseph","userId":"09266131455780899081"}},"outputId":"fd312607-8e40-4e2c-f053-98f01ccf3dc8"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["3"]},"metadata":{},"execution_count":78}]},{"cell_type":"code","source":["tensor.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"D5ymw0e4OSoY","executionInfo":{"status":"ok","timestamp":1751214910789,"user_tz":-60,"elapsed":5,"user":{"displayName":"Asttle Joseph","userId":"09266131455780899081"}},"outputId":"29bf966d-c389-437a-b014-d9d8406019e2"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([2, 3, 3])"]},"metadata":{},"execution_count":79}]},{"cell_type":"code","source":["#Random tensors - these are way to make deep nn learn starting with random and lookup data evaluate and again radomise loop\n","random_tensor = torch.rand(3,4)\n","print(random_tensor)\n","print(random_tensor.ndim)\n","print(tensor.dtype)"],"metadata":{"id":"2S7hbN5gOTz_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1751214910789,"user_tz":-60,"elapsed":3,"user":{"displayName":"Asttle Joseph","userId":"09266131455780899081"}},"outputId":"bd8f2ed5-ee6a-4677-8c53-9b34a1ec1975"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[0.7118, 0.7876, 0.4183, 0.9014],\n","        [0.9969, 0.7565, 0.2239, 0.3023],\n","        [0.1784, 0.8238, 0.5557, 0.9770]])\n","2\n","torch.int64\n"]}]},{"cell_type":"code","source":["#zeros and ones\n","zeros_tensor = torch.zeros(3,4)\n","print(zeros_tensor)\n","zeros_tensor.dtype"],"metadata":{"id":"PC3PLjvGvCib","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1751214910793,"user_tz":-60,"elapsed":4,"user":{"displayName":"Asttle Joseph","userId":"09266131455780899081"}},"outputId":"9c010700-3be0-464d-dc97-6f9d12132d37"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[0., 0., 0., 0.],\n","        [0., 0., 0., 0.],\n","        [0., 0., 0., 0.]])\n"]},{"output_type":"execute_result","data":{"text/plain":["torch.float32"]},"metadata":{},"execution_count":81}]},{"cell_type":"code","source":["# range of tensors and tensors like\n","range_tensor = torch.arange(1,11, 1) # range is deprecated so use arange\n","print(range_tensor)\n","zeros_like = torch.zeros_like(range_tensor)\n","print(zeros_like)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Jc3XJu7eob2A","executionInfo":{"status":"ok","timestamp":1751214910802,"user_tz":-60,"elapsed":10,"user":{"displayName":"Asttle Joseph","userId":"09266131455780899081"}},"outputId":"7410bd55-cc58-4b07-ebcd-ccd03430579a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n"]}]},{"cell_type":"markdown","source":["Data types in tensors\n","This is where a lot of errors will be faced when it comes to pytorcha nd deep learning\n","1. tensors not in right datatype - if one tensor is float 32 and other is float16 we'll get errors\n","2. tensors not in right device - if one tensor is in cuda and other in cpu\n","3. tensors not in right shape - one is 8 and otehr is 10\n"],"metadata":{"id":"vLMTxMQss0Rx"}},{"cell_type":"code","source":["# tensor datatypes\n","# flat32 tensor\n","float_32_tensor = torch.tensor([3.0,4.0,5.0], dtype=None) # even if we specify None torch will emit float 32\n","print(float_32_tensor)\n","float_16_tensor = torch.tensor([3.0,5.0,7.0], dtype=torch.float16)\n","print(float_16_tensor)\n","print(float_16_tensor.dtype)\n","tensor_params = torch.tensor([1.0,2.0,3.0], dtype=None, device=None, requires_grad=False) # whether to track gradients with this tensor operation (requires_grad)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dQvdDqluqfEe","executionInfo":{"status":"ok","timestamp":1751214910837,"user_tz":-60,"elapsed":42,"user":{"displayName":"Asttle Joseph","userId":"09266131455780899081"}},"outputId":"da3aeb12-567a-4ac5-98b6-24fd1a247a63"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([3., 4., 5.])\n","tensor([3., 5., 7.], dtype=torch.float16)\n","torch.float16\n"]}]},{"cell_type":"code","source":["# type conversion\n","float32_tensor = torch.tensor([10,20], dtype=None)\n","float16_tensor = float32_tensor.type(torch.float16)\n","mul = float32_tensor * float16_tensor\n","print(mul) # it works looks like our rule is wrong - we'll get errors if we are not in right datatype but actually its only for same datatype diff dt still throws errpr\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9_2_7QBetaDx","executionInfo":{"status":"ok","timestamp":1751214910837,"user_tz":-60,"elapsed":5,"user":{"displayName":"Asttle Joseph","userId":"09266131455780899081"}},"outputId":"efc9be8b-183c-4788-9e9a-0595f6cc844c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([100., 400.], dtype=torch.float16)\n"]}]},{"cell_type":"markdown","source":["# manipulating tensors (tensor operations)\n","tensor operations include add, sub, mul (element-wise), div"],"metadata":{"id":"99e8vHg5F_Me"}},{"cell_type":"code","source":["tensoradd = torch.tensor([1,2,3])\n","tensoradd = tensoradd.add(10)\n","print(tensoradd)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dEMKn8NfF6Ir","executionInfo":{"status":"ok","timestamp":1751214910838,"user_tz":-60,"elapsed":3,"user":{"displayName":"Asttle Joseph","userId":"09266131455780899081"}},"outputId":"c5f4ea5b-450c-4a33-a29f-6e4aa64ed61e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([11, 12, 13])\n"]}]},{"cell_type":"code","source":["tensorsub = torch.tensor([1,2,3])\n","tensorsub = tensorsub.sub(1)\n","print(tensorsub)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q7odKPCIHqDy","executionInfo":{"status":"ok","timestamp":1751214910843,"user_tz":-60,"elapsed":6,"user":{"displayName":"Asttle Joseph","userId":"09266131455780899081"}},"outputId":"0adb8ebe-ad4d-404e-8923-880541a6a68c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([0, 1, 2])\n"]}]},{"cell_type":"code","source":["# tensor multiplication\n","# Element wise mul\n","elmul_tensor = torch.tensor([1,2,3])\n","print(f\"Element wise mul{elmul_tensor * elmul_tensor}\")\n","matmul_tensor = torch.tensor([[1,2,3],[4,5,6],[7,8,9]])\n","print(f\"Matrix mul{torch.matmul(matmul_tensor, matmul_tensor)}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4lp9pnA7H9lG","executionInfo":{"status":"ok","timestamp":1751214910845,"user_tz":-60,"elapsed":2,"user":{"displayName":"Asttle Joseph","userId":"09266131455780899081"}},"outputId":"3f6592a8-c693-49f4-a760-a2b46bc7b2ec"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Element wise multensor([1, 4, 9])\n","Matrix multensor([[ 30,  36,  42],\n","        [ 66,  81,  96],\n","        [102, 126, 150]])\n"]}]},{"cell_type":"code","source":["# comparing time it takes between normal matrix mul vs tensor matrix multiplication\n","%%time\n","time1 = torch.tensor([1,2,3])\n","matmulres1 = 0\n","for i in range(len(time1)):\n","  matmulres1 += time1[i] * time1[i]\n","print(matmulres1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xkKG8hXdB2vD","executionInfo":{"status":"ok","timestamp":1751214910868,"user_tz":-60,"elapsed":22,"user":{"displayName":"Asttle Joseph","userId":"09266131455780899081"}},"outputId":"cd28cee6-72a3-478f-b723-b5ca1366c6d6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(14)\n","CPU times: user 809 µs, sys: 0 ns, total: 809 µs\n","Wall time: 1.27 ms\n"]}]},{"cell_type":"code","source":["%%time\n","time2 = torch.tensor([1,2,3])\n","torch.matmul(time2, time2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8gwco0RjC9-2","executionInfo":{"status":"ok","timestamp":1751214910871,"user_tz":-60,"elapsed":10,"user":{"displayName":"Asttle Joseph","userId":"09266131455780899081"}},"outputId":"ca028c55-7977-4fa3-bbd7-54a289b238ba"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["CPU times: user 102 µs, sys: 7 µs, total: 109 µs\n","Wall time: 114 µs\n"]},{"output_type":"execute_result","data":{"text/plain":["tensor(14)"]},"metadata":{},"execution_count":89}]},{"cell_type":"markdown","source":["# Rules of matrix multiplication\n","1. Inner dimesnions mutch match or else we will get into error\n","eg (2,3) (3,2) will work and not (3,2) and (3,2)\n","2. The resultant matrix will always have the ouyter shape of the matrix\n","for example (2,3) and (3,2) will result in 2X2 matrix and even (3,10) and (10,3) will result in 3X3 matrix"],"metadata":{"id":"UwDOXSyrEMO-"}},{"cell_type":"markdown","source":["Transpose"],"metadata":{"id":"nTHm2YSeutK6"}},{"cell_type":"code","source":["# to solve matrix shape problems lets transpose the matrix to fix the issues\n","matrix_a = torch.tensor([[1,2,3],[3,4,5]])\n","matrix_b = torch.tensor([[1,2,3],[3,4,5]]) # 3x2 matrix\n","print(torch.matmul(matrix_a, matrix_b.T))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G1XBC8TDEmHc","executionInfo":{"status":"ok","timestamp":1751214910871,"user_tz":-60,"elapsed":7,"user":{"displayName":"Asttle Joseph","userId":"09266131455780899081"}},"outputId":"f810d57d-de73-49e7-fb5e-a69835127090"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[14, 26],\n","        [26, 50]])\n"]}]},{"cell_type":"markdown","source":["Tensor Aggregation\n","Finding the min, max, mean and sum"],"metadata":{"id":"Lqv5uBYvv5fY"}},{"cell_type":"code","source":["x = torch.arange(0,100,10)\n","print(x)\n","print(x.min(), torch.min(x))\n","print(x.max(), torch.max(x))\n","print(x.type(torch.float32).mean(), torch.mean(x.type(torch.float32)))\n","print(x.sum(), torch.sum(x))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jMdB9njDuvte","executionInfo":{"status":"ok","timestamp":1751214910872,"user_tz":-60,"elapsed":6,"user":{"displayName":"Asttle Joseph","userId":"09266131455780899081"}},"outputId":"179c152a-9b6e-4486-aead-1f28f54708a5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90])\n","tensor(0) tensor(0)\n","tensor(90) tensor(90)\n","tensor(45.) tensor(45.)\n","tensor(450) tensor(450)\n"]}]},{"cell_type":"code","source":["# index of min and max\n","x = torch.arange(0,100,10)\n","print(torch.argmin(x), torch.argmax(x))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wgr2O2Fatajg","executionInfo":{"status":"ok","timestamp":1751214910872,"user_tz":-60,"elapsed":3,"user":{"displayName":"Asttle Joseph","userId":"09266131455780899081"}},"outputId":"a4b3e39f-5622-4f50-869b-3c636cbaf509"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(0) tensor(9)\n"]}]},{"cell_type":"markdown","source":["Reshaping, stacking, squeezing and unsqueezing tensors\n","1. Reshaping - reshapes an input tensor to a defined shape\n","2. View - Return a view of the input tensor of certain shape but keep the same memory as the original tensor\n","3. Stacking - combine multiple tensors on top of each other(vstack) or side by side (hstack)\n","4. Squeeze - removes all '1' dimesnions from the sensor\n","5. Unsquueze - add a '1' dimensions to a target tensor\n","6. Permute - return a view of the input with dimensions permuted (swapped) in a certain way\n","\n"],"metadata":{"id":"xC6bm3O1x1eg"}},{"cell_type":"code","source":["x = torch.arange(0., 10.)\n","print(x, x.shape)\n","# reshape would only work if you dont shape the size of the original tensor\n","x_reshape1 = x.reshape(5,2)\n","print(x_reshape1, x_reshape1.shape)\n","x_reshape2 = x.reshape(2,5)\n","print(x_reshape2, x_reshape2.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4eYp5canx6yy","executionInfo":{"status":"ok","timestamp":1751214910899,"user_tz":-60,"elapsed":2,"user":{"displayName":"Asttle Joseph","userId":"09266131455780899081"}},"outputId":"88cc3e45-db10-4a3b-c8ae-b307481523c7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([0., 1., 2., 3., 4., 5., 6., 7., 8., 9.]) torch.Size([10])\n","tensor([[0., 1.],\n","        [2., 3.],\n","        [4., 5.],\n","        [6., 7.],\n","        [8., 9.]]) torch.Size([5, 2])\n","tensor([[0., 1., 2., 3., 4.],\n","        [5., 6., 7., 8., 9.]]) torch.Size([2, 5])\n"]}]},{"cell_type":"code","source":["# view takes a deep copy of original tensor so any changes to view tensor will change the original tensor as well\n","tensor = torch.arange(0.,10.)\n","print(tensor, tensor.shape)\n","tensor_view = tensor.view(5,2)\n","print(tensor_view, tensor_view.shape)\n","tensor_view[:,0] = 5 # changes all 0th index of all vectors to 5\n","print(tensor_view, tensor_view.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q5s00wUb2b-b","executionInfo":{"status":"ok","timestamp":1751214910910,"user_tz":-60,"elapsed":10,"user":{"displayName":"Asttle Joseph","userId":"09266131455780899081"}},"outputId":"bab6474c-73a4-4065-b7f3-2e7bec73a2f3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([0., 1., 2., 3., 4., 5., 6., 7., 8., 9.]) torch.Size([10])\n","tensor([[0., 1.],\n","        [2., 3.],\n","        [4., 5.],\n","        [6., 7.],\n","        [8., 9.]]) torch.Size([5, 2])\n","tensor([[5., 1.],\n","        [5., 3.],\n","        [5., 5.],\n","        [5., 7.],\n","        [5., 9.]]) torch.Size([5, 2])\n"]}]},{"cell_type":"code","source":["# stack tensors on top of each other\n","tensor = torch.arange(0.,10.)\n","print(tensor, tensor.shape)\n","tensor_stacked = torch.stack([tensor, tensor, tensor], dim=1)\n","print(tensor_stacked, tensor_stacked.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"noX4A2VW3Dht","executionInfo":{"status":"ok","timestamp":1751214910910,"user_tz":-60,"elapsed":8,"user":{"displayName":"Asttle Joseph","userId":"09266131455780899081"}},"outputId":"b67d9095-fc81-433e-e291-5ce0ef9ae7fe"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([0., 1., 2., 3., 4., 5., 6., 7., 8., 9.]) torch.Size([10])\n","tensor([[0., 0., 0.],\n","        [1., 1., 1.],\n","        [2., 2., 2.],\n","        [3., 3., 3.],\n","        [4., 4., 4.],\n","        [5., 5., 5.],\n","        [6., 6., 6.],\n","        [7., 7., 7.],\n","        [8., 8., 8.],\n","        [9., 9., 9.]]) torch.Size([10, 3])\n"]}]},{"cell_type":"code","source":["# squeeze tensors - remove all single dimesions from a target tensor\n","tensor = torch.tensor([[3],[5],[7]])\n","print(tensor, tensor.squeeze())\n","print(tensor.shape, tensor.squeeze().shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zqLQFta-4Wt6","executionInfo":{"status":"ok","timestamp":1751214910910,"user_tz":-60,"elapsed":6,"user":{"displayName":"Asttle Joseph","userId":"09266131455780899081"}},"outputId":"6db8be2c-eca6-4e60-8ec7-baf1c0617fb8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[3],\n","        [5],\n","        [7]]) tensor([3, 5, 7])\n","torch.Size([3, 1]) torch.Size([3])\n"]}]},{"cell_type":"code","source":["# unsqueee tensors - add omne dimension to the target tensor\n","tensor = torch.tensor([1,2,3,5,6,7,8,9])\n","print(tensor, tensor.unsqueeze(dim=0))\n","print(tensor, tensor.unsqueeze(dim=1))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SrIN1zM46mUv","executionInfo":{"status":"ok","timestamp":1751214911149,"user_tz":-60,"elapsed":242,"user":{"displayName":"Asttle Joseph","userId":"09266131455780899081"}},"outputId":"e9e100d8-9044-4b1e-c96b-c76b5f058897"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([1, 2, 3, 5, 6, 7, 8, 9]) tensor([[1, 2, 3, 5, 6, 7, 8, 9]])\n","tensor([1, 2, 3, 5, 6, 7, 8, 9]) tensor([[1],\n","        [2],\n","        [3],\n","        [5],\n","        [6],\n","        [7],\n","        [8],\n","        [9]])\n"]}]},{"cell_type":"code","source":["# permute tensors - rearrange the dimensions in the tensor in a specific way\n","original_tensor = torch.rand(size=(224,224,3))\n","print(original_tensor.shape)\n","permuted_tensor = original_tensor.permute(2,0,1)\n","print(permuted_tensor.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bP9_czJ7ntkW","executionInfo":{"status":"ok","timestamp":1751214911150,"user_tz":-60,"elapsed":10,"user":{"displayName":"Asttle Joseph","userId":"09266131455780899081"}},"outputId":"1b13ddfd-7e18-4bc9-89af-1586499d9ab0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([224, 224, 3])\n","torch.Size([3, 224, 224])\n"]}]},{"cell_type":"markdown","source":["Pytorch and Numpy\n","\n","Numpy is popular scientific puthon numerical computing library so\n","Pytorch has compatibility to load data from numpy and change tensor to numpy\n","torch.from_numpy(ndarray)\n","torch.Tensor.numpy()\n"],"metadata":{"id":"q0IlHXfCubEC"}},{"cell_type":"code","source":["import torch\n","import numpy as np\n","\n","array = np.arange(1.0, 8.0)\n","tensor = torch.from_numpy(array) # when converting numpy default dtupe ios float 64 which will be passed to tensor\n","print(array, array.dtype, tensor)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ojcvZs3kucja","executionInfo":{"status":"ok","timestamp":1751214911150,"user_tz":-60,"elapsed":7,"user":{"displayName":"Asttle Joseph","userId":"09266131455780899081"}},"outputId":"dfe27456-94aa-4aea-e65c-e094e1b4d43c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[1. 2. 3. 4. 5. 6. 7.] float64 tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64)\n"]}]},{"cell_type":"markdown","source":["Numpy and torch tensor doesnt share memory which means one value does not change the other\n","And default type of tensor float32 will be applied to numpy if we convert to that"],"metadata":{"id":"XZefAdU8wky7"}},{"cell_type":"markdown","source":["## Pytorch reproducability ( taking out the random out of random)\n","\n","in short how a newural network leans is:\n","\n","`start with random numbers -> tensor operations -> update random numbers to try and make them better representations of data -> again -> again -> again...`\n","\n","\n","To reduce the randomness in neural networks and PyTorch comes the concept of a **random seed**\n","\n","Essentially what the random seed does is \"flavour\" the randomness.\n","\n","Pseudo randomness - random without any means just the rand method"],"metadata":{"id":"U8mmx050xTBf"}},{"cell_type":"code","source":["import torch\n","\n","# create two random tensors\n","\n","random_tensor_A = torch.rand(3,4)\n","random_tensor_B = torch.rand(3,4)\n","\n","print(random_tensor_A)\n","print(random_tensor_B)\n","print(random_tensor_A == random_tensor_B)\n","\n","RANDOM_SEED = 100\n","torch.manual_seed(RANDOM_SEED)\n","random_tensor_C = torch.rand(3,4)\n","torch.manual_seed(RANDOM_SEED)\n","random_tensor_D = torch.rand(3,4)\n","\n","print(random_tensor_C)\n","print(random_tensor_D)\n","print(random_tensor_C == random_tensor_D)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PaJFlVrgwqqi","executionInfo":{"status":"ok","timestamp":1751214911150,"user_tz":-60,"elapsed":4,"user":{"displayName":"Asttle Joseph","userId":"09266131455780899081"}},"outputId":"efeb4c0e-2df5-4ea0-8a30-7d6e03b90eb1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[0.2089, 0.7017, 0.5200, 0.8843],\n","        [0.8486, 0.7041, 0.1515, 0.7470],\n","        [0.5887, 0.6700, 0.1507, 0.5938]])\n","tensor([[0.2676, 0.2770, 0.5603, 0.8046],\n","        [0.0534, 0.1003, 0.1376, 0.5909],\n","        [0.5555, 0.4608, 0.7407, 0.1953]])\n","tensor([[False, False, False, False],\n","        [False, False, False, False],\n","        [False, False, False, False]])\n","tensor([[0.1117, 0.8158, 0.2626, 0.4839],\n","        [0.6765, 0.7539, 0.2627, 0.0428],\n","        [0.2080, 0.1180, 0.1217, 0.7356]])\n","tensor([[0.1117, 0.8158, 0.2626, 0.4839],\n","        [0.6765, 0.7539, 0.2627, 0.0428],\n","        [0.2080, 0.1180, 0.1217, 0.7356]])\n","tensor([[True, True, True, True],\n","        [True, True, True, True],\n","        [True, True, True, True]])\n"]}]},{"cell_type":"markdown","source":["Running tensors and pytorch objects on GPUs (and making faster computations)\n","GPUs = faster computation on numbers, CUDA + NVIDIA hardware + pytorch"],"metadata":{"id":"IK_6_jjH3uE8"}},{"cell_type":"markdown","source":["## Getting a GPU\n","1. Easiest - Google colab for free GPU (options to upgrade)\n","2. Setting your own GPU - takes effort and investment\n","3. use cloud\n","Foe 2,3 we need pytorch, gpu driver (CUDA)"],"metadata":{"id":"v-52pvbFh4de"}},{"cell_type":"code","source":["!nvidia-smi"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j6D_p5_Uhr_3","executionInfo":{"status":"ok","timestamp":1751214911163,"user_tz":-60,"elapsed":15,"user":{"displayName":"Asttle Joseph","userId":"09266131455780899081"}},"outputId":"49cfc96a-f3cd-499d-dc7f-748fcd5efaa6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Sun Jun 29 16:35:10 2025       \n","+-----------------------------------------------------------------------------------------+\n","| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n","|-----------------------------------------+------------------------+----------------------+\n","| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n","|                                         |                        |               MIG M. |\n","|=========================================+========================+======================|\n","|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n","| N/A   36C    P8              9W /   70W |       2MiB /  15360MiB |      0%      Default |\n","|                                         |                        |                  N/A |\n","+-----------------------------------------+------------------------+----------------------+\n","                                                                                         \n","+-----------------------------------------------------------------------------------------+\n","| Processes:                                                                              |\n","|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n","|        ID   ID                                                               Usage      |\n","|=========================================================================================|\n","|  No running processes found                                                             |\n","+-----------------------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","source":["# Check for GPU access with PyTorch\n","import torch\n","torch.cuda.is_available()"],"metadata":{"id":"cA8gW73-iNeu","executionInfo":{"status":"ok","timestamp":1751214911171,"user_tz":-60,"elapsed":12,"user":{"displayName":"Asttle Joseph","userId":"09266131455780899081"}},"outputId":"7438bccb-4fc1-4887-c47f-780545ee348f","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":102}]},{"cell_type":"code","source":["# Device agnostic code\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","device"],"metadata":{"id":"iG9r8nwnifxX","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1751214931379,"user_tz":-60,"elapsed":45,"user":{"displayName":"Asttle Joseph","userId":"09266131455780899081"}},"outputId":"8be78f75-b7c4-4e29-ba77-99de37b2ce6b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'cuda'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":105}]},{"cell_type":"markdown","source":["Putting tensors and models on gpu\n","Main reason it is faster for computation"],"metadata":{"id":"imhenTESj7TU"}},{"cell_type":"code","source":["tensor = torch.tensor([1,2,3])\n","print(tensor, tensor.device)\n","\n","tensor_on_gpu = tensor.to(device)\n","print(tensor_on_gpu, tensor_on_gpu.device)\n","\n","tensor_back_on_cpu = tensor_on_gpu.cpu().numpy()\n","print(tensor_back_on_cpu, tensor_back_on_cpu.device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6_wXIz7Kkj7O","executionInfo":{"status":"ok","timestamp":1751215503076,"user_tz":-60,"elapsed":17,"user":{"displayName":"Asttle Joseph","userId":"09266131455780899081"}},"outputId":"6ff66201-9007-4d50-8aff-0a7569130e61"},"execution_count":109,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([1, 2, 3]) cpu\n","tensor([1, 2, 3], device='cuda:0') cuda:0\n","[1 2 3] cpu\n"]}]}]}